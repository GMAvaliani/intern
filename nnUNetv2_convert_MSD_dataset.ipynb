{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnUNet_raw: C:\\УИИ\\Internship\\-Task06_Lung\\Task06_Lung\n",
      "nnUNet_preprocessed: None\n",
      "nnUNet_results: None\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import multiprocessing\n",
    "import shutil\n",
    "from multiprocessing import Pool\n",
    "from typing import Optional\n",
    "import SimpleITK as sitk\n",
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "\n",
    "from nnunetv2.paths import nnUNet_raw, nnUNet_preprocessed, nnUNet_results\n",
    "\n",
    "from nnunetv2.utilities.dataset_name_id_conversion import find_candidate_datasets\n",
    "from nnunetv2.configuration import default_num_processes\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def split_4d_nifti(filename, output_folder):\n",
    "    img_itk = sitk.ReadImage(filename)\n",
    "    dim = img_itk.GetDimension()\n",
    "    file_base = os.path.basename(filename)\n",
    "    if dim == 3:\n",
    "        shutil.copy(filename, join(output_folder, file_base[:-7] + \"_0000.nii.gz\"))\n",
    "        return\n",
    "    elif dim != 4:\n",
    "        raise RuntimeError(\"Unexpected dimensionality: %d of file %s, cannot split\" % (dim, filename))\n",
    "    else:\n",
    "        img_npy = sitk.GetArrayFromImage(img_itk)\n",
    "        spacing = img_itk.GetSpacing()\n",
    "        origin = img_itk.GetOrigin()\n",
    "        direction = np.array(img_itk.GetDirection()).reshape(4,4)\n",
    "        # now modify these to remove the fourth dimension\n",
    "        spacing = tuple(list(spacing[:-1]))\n",
    "        origin = tuple(list(origin[:-1]))\n",
    "        direction = tuple(direction[:-1, :-1].reshape(-1))\n",
    "        for i, t in enumerate(range(img_npy.shape[0])):\n",
    "            img = img_npy[t]\n",
    "            img_itk_new = sitk.GetImageFromArray(img)\n",
    "            img_itk_new.SetSpacing(spacing)\n",
    "            img_itk_new.SetOrigin(origin)\n",
    "            img_itk_new.SetDirection(direction)\n",
    "            sitk.WriteImage(img_itk_new, join(output_folder, file_base[:-7] + \"_%04.0d.nii.gz\" % i))\n",
    "\n",
    "\n",
    "def convert_msd_dataset(source_folder: str, overwrite_target_id: Optional[int] = None,\n",
    "                        num_processes: int = default_num_processes) -> None:\n",
    "\n",
    "    print(\"nnUNet_raw:\", nnUNet_raw)\n",
    "    print(\"nnUNet_preprocessed:\", nnUNet_preprocessed)\n",
    "    print(\"nnUNet_results:\", nnUNet_results)\n",
    "\n",
    "    if source_folder.endswith('/') or source_folder.endswith('\\\\'):\n",
    "        source_folder = source_folder[:-1]\n",
    "\n",
    "    labelsTr = \"C:\\\\УИИ\\\\Internship\\\\-Task06_Lung\\\\Task06_Lung\\\\labelsTr\"  # Путь, который нужно поменять\n",
    "    imagesTs = \"C:\\\\УИИ\\\\Internship\\\\-Task06_Lung\\\\Task06_Lung\\\\imagesTs\"  # Путь, который нужно поменять\n",
    "    imagesTr = \"C:\\\\УИИ\\\\Internship\\\\-Task06_Lung\\\\Task06_Lung\\\\imagesTr\"  # Путь, который нужно поменять\n",
    "\n",
    "\n",
    "    assert isdir(labelsTr), f\"labelsTr subfolder missing in source folder\"\n",
    "    assert isdir(imagesTs), f\"imagesTs subfolder missing in source folder\"\n",
    "    assert isdir(imagesTr), f\"imagesTr subfolder missing in source folder\"\n",
    "    dataset_json = join(source_folder, 'dataset.json')\n",
    "    assert isfile(dataset_json), f\"dataset.json missing in source_folder\"\n",
    "\n",
    "    # infer source dataset id and name\n",
    "    task, dataset_name = os.path.basename(source_folder).split('_')\n",
    "    task_id = int(task[4:])\n",
    "\n",
    "    # check if target dataset id is taken\n",
    "    target_id = task_id if overwrite_target_id is None else overwrite_target_id\n",
    "    existing_datasets = find_candidate_datasets(target_id)\n",
    "    assert len(existing_datasets) == 0, f\"Target dataset id {target_id} is already taken, please consider changing \" \\\n",
    "                                        f\"it using overwrite_target_id. Conflicting dataset: {existing_datasets} (check nnUNet_results, nnUNet_preprocessed and nnUNet_raw!)\"\n",
    "\n",
    "    target_dataset_name = f\"Dataset{target_id:03d}_{dataset_name}\"\n",
    "    target_folder = join(nnUNet_raw, target_dataset_name)\n",
    "    target_imagesTr = join(target_folder, 'imagesTr')\n",
    "    target_imagesTs = join(target_folder, 'imagesTs')\n",
    "    target_labelsTr = join(target_folder, 'labelsTr')\n",
    "    maybe_mkdir_p(target_imagesTr)\n",
    "    maybe_mkdir_p(target_imagesTs)\n",
    "    maybe_mkdir_p(target_labelsTr)\n",
    "\n",
    "    with multiprocessing.get_context(\"spawn\").Pool(num_processes) as p:\n",
    "        results = []\n",
    "\n",
    "        # convert 4d train images\n",
    "        source_images = [i for i in subfiles(imagesTr, suffix='.nii.gz', join=False) if\n",
    "                         not i.startswith('.') and not i.startswith('_')]\n",
    "        source_images = [join(imagesTr, i) for i in source_images]\n",
    "\n",
    "        results.append(\n",
    "            p.starmap_async(\n",
    "                split_4d_nifti, zip(source_images, [target_imagesTr] * len(source_images))\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # convert 4d test images\n",
    "        source_images = [i for i in subfiles(imagesTs, suffix='.nii.gz', join=False) if\n",
    "                         not i.startswith('.') and not i.startswith('_')]\n",
    "        source_images = [join(imagesTs, i) for i in source_images]\n",
    "\n",
    "        results.append(\n",
    "            p.starmap_async(\n",
    "                split_4d_nifti, zip(source_images, [target_imagesTs] * len(source_images))\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # copy segmentations\n",
    "        source_images = [i for i in subfiles(labelsTr, suffix='.nii.gz', join=False) if\n",
    "                         not i.startswith('.') and not i.startswith('_')]\n",
    "        for s in source_images:\n",
    "            shutil.copy(join(labelsTr, s), join(target_labelsTr, s))\n",
    "\n",
    "        [i.get() for i in results]\n",
    "\n",
    "    dataset_json = load_json(dataset_json)\n",
    "    dataset_json['labels'] = {j: int(i) for i, j in dataset_json['labels'].items()}\n",
    "    dataset_json['file_ending'] = \".nii.gz\"\n",
    "    dataset_json[\"channel_names\"] = dataset_json[\"modality\"]\n",
    "    del dataset_json[\"modality\"]\n",
    "    del dataset_json[\"training\"]\n",
    "    del dataset_json[\"test\"]\n",
    "    save_json(dataset_json, join(nnUNet_raw, target_dataset_name, 'dataset.json'), sort_keys=False)\n",
    "\n",
    "\n",
    "def entry_point():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('-i', type=str, required=True,\n",
    "                        help='Downloaded and extracted MSD dataset folder. CANNOT be nnUNetv1 dataset! Example: '\n",
    "                             '/content/drive/MyDrive/Task24_Lung')\n",
    "    parser.add_argument('-overwrite_id', type=int, required=False, default=None,\n",
    "                        help='Overwrite the dataset id. If not set we use the id of the MSD task (inferred from '\n",
    "                             'folder name). Only use this if you already have an equivalently numbered dataset!')\n",
    "    parser.add_argument('-np', type=int, required=False, default=default_num_processes,\n",
    "                        help=f'Number of processes used. Default: {default_num_processes}')\n",
    "    args = parser.parse_args()\n",
    "    convert_msd_dataset(args.i, args.overwrite_id, args.np)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    nnUNet_raw = \"C:\\\\УИИ\\\\Internship\\\\-Task06_Lung\\\\Task06_Lung\"  # Путь, который нужно поменять\n",
    "    convert_msd_dataset('C:\\\\УИИ\\\\Internship\\\\-Task06_Lung\\\\Task06_Lung', overwrite_target_id=201)  # Путь, который нужно поменять\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код предназначен для обработки и преобразования наборов данных, для разделения 4D изображений на отдельные 3D изображения. Он также выполняет ряд проверок структуры каталогов и обновляет метаданные набора данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Импорты:\n",
    "Код начинается с импортирования различных библиотек и модулей, таких как argparse (для обработки аргументов командной строки), multiprocessing (для параллельных вычислений), SimpleITK (для работы с изображениями в формате ITK) и других. Особенно важны импорты из nnunetv2, так как они связаны с основной функциональностью кода.\n",
    "\n",
    "2. Функция split_4d_nifti:\n",
    "Эта функция принимает имя файла и папку назначения. Если изображение трёхмерное, оно просто копируется в папку назначения. Если изображение четырёхмерное, оно разделяется на отдельные трёхмерные изображения, и каждое из них сохраняется в папке назначения.\n",
    "\n",
    "3. Функция convert_msd_dataset:\n",
    "Эта функция выполняет основную работу:\n",
    "Сначала она проверяет структуру каталогов исходной папки (source_folder), чтобы убедиться, что все необходимые подпапки (labelsTr, imagesTs, imagesTr) присутствуют.\n",
    "Определяется исходный идентификатор набора данных и его имя на основе имени каталога.\n",
    "Создаются новые папки в каталоге nnUNet_raw.\n",
    "С помощью многозадачности выполняется разделение 4D изображений на отдельные 3D изображения с использованием функции split_4d_nifti.\n",
    "Файлы сегментации копируются без изменений.\n",
    "Информация о наборе данных (файл dataset.json) обновляется и сохраняется.\n",
    "\n",
    "4. Функция entry_point:\n",
    "Эта функция предназначена для обработки аргументов командной строки и вызова функции convert_msd_dataset. Это основная точка входа, если бы мы запускали код как скрипт из командной строки.\n",
    "\n",
    "5. Условие if __name__ == '__main__'::\n",
    "Это условие гарантирует, что код внутри него будет выполнен только если вы запускаете файл напрямую (а не импортируете как модуль). В вашем случае, этот блок просто вызывает функцию convert_msd_dataset с фиксированными аргументами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результатом работы вашего кода будет преобразование исходного набора данных в новый формат, который будет соответствовать структуре каталогов и требованиям nnUNet. Вот основные результаты действий кода:\n",
    "\n",
    "Преобразование 4D изображений:\n",
    "\n",
    "Если набор данных содержит 4D изображения (например, временные последовательности 3D изображений), они будут разделены на отдельные 3D изображения.\n",
    "Эти новые 3D изображения будут сохранены с новыми именами файлов в соответствующих папках imagesTr и imagesTs.\n",
    "Копирование Сегментаций:\n",
    "\n",
    "Файлы сегментации из папки labelsTr исходного набора данных будут скопированы без изменений в новую папку labelsTr в каталоге nnUNet_raw.\n",
    "Обновление информации о наборе данных:\n",
    "\n",
    "Файл dataset.json исходного набора данных будет обновлен, чтобы соответствовать новой структуре, и сохранен в новом местоположении в каталоге nnUNet_raw.\n",
    "Создание новых каталогов:\n",
    "\n",
    "Будет создана новая структура каталогов в директории nnUNet_raw под именем DatasetXXX_ИмяНабораДанных, где XXX — это идентификатор набора данных, а ИмяНабораДанных — это имя, извлеченное из исходного набора данных.\n",
    "Таким образом, в конечном итоге у вас будет новый набор данных, готовый к дальнейшему использованию с nnUNet, с разделенными 4D изображениями и обновленной информацией о наборе данных."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
